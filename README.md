# Multilingual Transformers in Code-Mixed Speech and Text: A Survey Across Core NLP Tasks

# âœ¨ Highlights
Code-mixing, the practice of alternating between two or more languages within a single utterance or text, is 
increasingly common in multilingual societies, particularly in informal settings such as social media, conversation, and 
user-generated content. This work provides a comprehensive overview of how modern multilingual transformer-based 
models, especially language models (LMs), handle this phenomenon across key NLP tasks.


Code-Mixing Prevalence: Widely observed in social platforms, informal speech, and user content in multilingual 
regions.

Challenges for NLP: Traditional monolingual NLP models face difficulty due to:

* Lexical inconsistencies

* Syntactic variation

* Semantic ambiguity

Focus of the Survey: Reviews transformer-based solutions for handling code-mixed data on core NLP 
tasks. Key challenges, Model adaptations, Evaluation benchmarks, and Limitations of existing models analysed for each of
the following core NLP tasks.

|   **Speech-to-text**    | **Speaker identification** |
|:-----------------------:|:--------------------------:|
| **Text Classification** |  **Token Classification**  |



# ğŸš€ Quick Start
| S.No |  STEP  |                         PROCESS                          | 
|:----:|:------:|:--------------------------------------------------------:|
|  1.  |   ğŸ”§   |            [Environment Setup](docs/SETUP.md)            |
|  2.  | ğŸ§¹ğŸ“ŠğŸ”¤ |        [Data Preparation](docs/DOWNLOAD_DATA.md)         |
|  3.  |   ğŸ§   |  [Qualitative Analysis](notebooks/Qualitative-Analysis)  |
|  4.  |  ğŸ“ˆğŸ“‰  | [Quantitative Analysis](notebooks/Quantitative-Analysis) |


# âš™ï¸ OS Compatibility Validated

| Platform  | Supported |
|-----------|:---------:|
| ğŸªŸ Windows | âŒ        |
| ğŸ macOS   | âŒ        |
| ğŸ§ Linux   | âœ…        |


# ğŸ“– Citation
```
Barathi Ganesh HB and Ptaszynski Michal. 2025. Multilingual Transformers in Code-Mixed Speech and Text:
A Survey Across Core NLP Tasks. J. ACM XX, X, Article XXX (June 2025), 10 pages. https://doi.org/XXXXXXX.
XXXXXXX
```
