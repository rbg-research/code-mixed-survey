{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ab7644-8bfa-44d4-bfa5-df25d4bbcbaf",
   "metadata": {},
   "source": [
    "# Import required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b75f40c-244f-456b-bdeb-970a8000d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8be644-d601-422c-b436-4c68ed2bcc43",
   "metadata": {},
   "source": [
    "# Path Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ca21832-855d-4fb5-97d9-1f3ed64d8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../../data/Named-Entity-Recognition/\"\n",
    "language_pairs = {\n",
    "    \"ner_hineng\": \"Hindi-English\",\n",
    "    \"ner_msaea\": \"Modern Standard Arabic - EgyptArabic\",\n",
    "    \"ner_spaeng\": \"Spanish-English\"\n",
    "}\n",
    "\n",
    "ground_truth_csv = os.path.join(root_path, \"gt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b464c0-3c41-4b83-ad60-35b4dae20f2f",
   "metadata": {},
   "source": [
    "# Ground Truth Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8bbd828-d599-4262-a4cc-a44aebd60447",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in language_pairs:\n",
    "    test_file = os.path.join(root_path, key, \"dev.conll\")\n",
    "    with open(test_file, \"r+\") as read_file:\n",
    "        text = read_file.read()\n",
    "        lines = text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b17faef3-f9b8-4d94-b8d6-07dc5be47401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(text: str) -> str:\n",
    "    text = re.sub(r'https?://\\S+', '', text)\n",
    "    text = re.sub(r'^RT\\s*:\\s*', '', text)\n",
    "    text = re.sub(r'&\\w+;', ' ', text)\n",
    "    text = re.sub(r'&#\\d+;', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\u0600-\\u06FF]', '', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def parse_conll_for_lid():\n",
    "    words = []\n",
    "    labels = []\n",
    "    for key in language_pairs:\n",
    "        test_file = os.path.join(root_path, key, \"dev.conll\")\n",
    "\n",
    "        with open(test_file, \"r+\") as read_file:\n",
    "            text = read_file.read()\n",
    "            lines = text.split(\"\\n\")\n",
    "            \n",
    "        lines = [line for line in lines if len(line.strip())>1]\n",
    "        \n",
    "        for idx, line in enumerate(lines):\n",
    "            if \"sent_enum\" in line:\n",
    "                pass\n",
    "            else:\n",
    "                items = line.split(\"\\t\")\n",
    "                word = items[0].strip()\n",
    "                # word = preprocess_tweet(word)\n",
    "                label = items[-1]\n",
    "                label = label.replace(\"B-\", \"\")\n",
    "                label = label.replace(\"I-\", \"\")\n",
    "                if label == \"ORG\":\n",
    "                    label = \"ORGANISATION\"\n",
    "                if label == \"PER\":\n",
    "                    label = \"PERSON\"\n",
    "                if label == \"OTHER\":\n",
    "                    label = \"O\"\n",
    "                words.append(word)\n",
    "                labels.append(label)\n",
    "    temp_df = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"words\": words,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "    )\n",
    "    return temp_df            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bebb80d9-45cb-4ffd-8b0d-297280719a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(ground_truth_csv):\n",
    "    df = pd.read_csv(ground_truth_csv)\n",
    "else:\n",
    "    df = parse_conll_for_lid()\n",
    "    df.to_csv(ground_truth_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "436dd6a6-4ec5-42d7-9a8d-6e9fa39aec49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stupid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>move</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>considering</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>their</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150757</th>\n",
       "      <td>un</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150758</th>\n",
       "      <td>trabajo</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150759</th>\n",
       "      <td>de</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150760</th>\n",
       "      <td>verdad</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150761</th>\n",
       "      <td>!</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150762 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              words labels\n",
       "0            stupid      O\n",
       "1              move      O\n",
       "2                 ,      O\n",
       "3       considering      O\n",
       "4             their      O\n",
       "...             ...    ...\n",
       "150757           un      O\n",
       "150758      trabajo      O\n",
       "150759           de      O\n",
       "150760       verdad      O\n",
       "150761            !      O\n",
       "\n",
       "[150762 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe711f03-cd3c-4137-898f-e81b43a261ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORGANISATION',\n",
       " 'PERSON',\n",
       " 'PROD',\n",
       " 'O',\n",
       " 'EVENT',\n",
       " 'TITLE',\n",
       " 'TIME',\n",
       " 'LOC',\n",
       " 'GROUP',\n",
       " 'PLACE']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(df.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f708a-3d43-4a47-b536-fd84b6900c14",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05f43356-050b-4149-8ec5-05e3bd72fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models = [\n",
    "    (\"xlmr\", \"xlm-roberta-base\"),\n",
    "    (\"mdeberta\", \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"),\n",
    "    (\"labse\", \"setu4993/LaBSE\"),\n",
    "    (\"muril\", \"google/muril-base-cased\")\n",
    "]\n",
    "\n",
    "hf_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "696c7833-a149-4a8c-b9f3-6fc4e5849896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode sentences\n",
    "def encode_sentences(tokenizer, model, sentences, device):\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "    # print(encoded_input)\n",
    "    encoded_input = encoded_input.to(device)\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    return model_output.last_hidden_state[:, 0, :]\n",
    "\n",
    "# Zero-shot prediction\n",
    "def zero_shot_predict_single(text, tokenizer, model, label_embeddings, labels, device):\n",
    "    text_embedding = encode_sentences(tokenizer, model, [text], device)\n",
    "    cosine_similarities = F.cosine_similarity(text_embedding.unsqueeze(1), label_embeddings.unsqueeze(0), dim=2)\n",
    "    predicted_index = torch.argmax(cosine_similarities, dim=1).item()\n",
    "    return labels[predicted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfef6b19-cacf-406c-967e-06de0d5aaa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:902: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlmr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:902: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdeberta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:902: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:902: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "muril\n"
     ]
    }
   ],
   "source": [
    "#  Choose the model here (1-based index): 1 = XLM-R, 2 = mDeBERTa, 3 = LaBSE, 4 = MuRIL\n",
    "for index in range(1,5):\n",
    "    df = pd.read_csv(ground_truth_csv)\n",
    "    choose_model = index\n",
    "    key, model_name = available_models[choose_model - 1]\n",
    "    labels_list = ['PERSON', 'PLACE', 'O', 'GROUP', 'ORGANISATION', 'LOC', 'PROD', 'TITLE', 'TIME', 'EVENT']\n",
    "    descriptions = [\n",
    "        'The word is an entity and refers a person',\n",
    "        'The word is an entity and refers a place',\n",
    "        'The word is not an entity and refers standard word',\n",
    "        'The word is not an entity and refers a group',\n",
    "        'The word is not an entity and refers a organisation',\n",
    "        'The word is not an entity and refers a location',\n",
    "        'The word is not an entity and refers a product',\n",
    "        'The word is not an entity and refers a title',\n",
    "        'The word is not an entity and refers a time',\n",
    "        'The word is not an entity and refers an event'\n",
    "    ]\n",
    "    if key not in df.columns:\n",
    "        device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hf_token)\n",
    "        model = AutoModel.from_pretrained(model_name, use_auth_token=hf_token).to(device)\n",
    "        model.eval()\n",
    "\n",
    "        label_embeddings = encode_sentences(tokenizer, model, descriptions, device)\n",
    "\n",
    "        predictions = []\n",
    "        for idx, item in enumerate(df[\"words\"].tolist()):\n",
    "            try:\n",
    "                pred = zero_shot_predict_single(item, tokenizer, model, label_embeddings, labels_list, device)\n",
    "                predictions.append(pred)\n",
    "            except Exception as e:\n",
    "                print(f\"Exception for model {model_name} at idx {idx}: {e}\")\n",
    "                predictions.append(\"O\")\n",
    "\n",
    "        df[key] = predictions\n",
    "        df.to_csv(ground_truth_csv, index=False)\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ce6f1-c2cd-48ee-b52c-c552a980ea24",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17cd6d5c-a348-4a88-ad5e-c029544c042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ground_truth_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4328c129-8413-4fb4-b6f1-f12b5feddf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CLASSIFICATION REPORT: xlmr\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       EVENT     0.0007    0.0089    0.0014       224\n",
      "       GROUP     0.0000    0.0000    0.0000       474\n",
      "         LOC     0.0192    0.0008    0.0015      1241\n",
      "           O     0.9091    0.0001    0.0001    144120\n",
      "ORGANISATION     0.0024    0.1293    0.0046       588\n",
      "      PERSON     0.0281    0.0181    0.0220      2702\n",
      "       PLACE     0.0009    0.7519    0.0018       129\n",
      "        PROD     0.0061    0.0467    0.0109       428\n",
      "        TIME     0.0000    0.0000    0.0000       225\n",
      "       TITLE     0.0026    0.0111    0.0042       631\n",
      "\n",
      "    accuracy                         0.0017    150762\n",
      "   macro avg     0.0969    0.0967    0.0047    150762\n",
      "weighted avg     0.8697    0.0017    0.0006    150762\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CLASSIFICATION REPORT: mdeberta\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       EVENT     0.0007    0.0938    0.0014       224\n",
      "       GROUP     0.0029    0.1899    0.0057       474\n",
      "         LOC     0.0000    0.0000    0.0000      1241\n",
      "           O     0.0000    0.0000    0.0000    144120\n",
      "ORGANISATION     0.0000    0.0000    0.0000       588\n",
      "      PERSON     0.0229    0.2002    0.0411      2702\n",
      "       PLACE     0.0008    0.4264    0.0017       129\n",
      "        PROD     0.0000    0.0000    0.0000       428\n",
      "        TIME     0.0000    0.0000    0.0000       225\n",
      "       TITLE     0.0000    0.0000    0.0000       631\n",
      "\n",
      "    accuracy                         0.0047    150762\n",
      "   macro avg     0.0027    0.0910    0.0050    150762\n",
      "weighted avg     0.0004    0.0047    0.0008    150762\n",
      "\n",
      "\n",
      "CLASSIFICATION REPORT: labse\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       EVENT     0.0033    0.0670    0.0062       224\n",
      "       GROUP     0.0143    0.2764    0.0272       474\n",
      "         LOC     0.0000    0.0000    0.0000      1241\n",
      "           O     0.9453    0.0807    0.1487    144120\n",
      "ORGANISATION     0.0046    0.1071    0.0088       588\n",
      "      PERSON     0.0087    0.0041    0.0055      2702\n",
      "       PLACE     0.0025    0.5039    0.0051       129\n",
      "        PROD     0.0000    0.0000    0.0000       428\n",
      "        TIME     0.0015    0.4000    0.0029       225\n",
      "       TITLE     0.0064    0.2044    0.0123       631\n",
      "\n",
      "    accuracy                         0.0805    150762\n",
      "   macro avg     0.0986    0.1644    0.0217    150762\n",
      "weighted avg     0.9039    0.0805    0.1424    150762\n",
      "\n",
      "\n",
      "CLASSIFICATION REPORT: muril\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       EVENT     0.0010    0.2679    0.0021       224\n",
      "       GROUP     0.0041    0.1055    0.0080       474\n",
      "         LOC     0.0178    0.3529    0.0339      1241\n",
      "           O     0.9852    0.0009    0.0018    144120\n",
      "ORGANISATION     0.0055    0.1871    0.0107       588\n",
      "      PERSON     0.0313    0.0133    0.0187      2702\n",
      "       PLACE     0.0043    0.0078    0.0055       129\n",
      "        PROD     0.0024    0.1449    0.0048       428\n",
      "        TIME     0.0014    0.0489    0.0028       225\n",
      "       TITLE     0.0081    0.0254    0.0122       631\n",
      "\n",
      "    accuracy                         0.0061    150762\n",
      "   macro avg     0.1061    0.1154    0.0101    150762\n",
      "weighted avg     0.9426    0.0061    0.0025    150762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index in range(1,5):\n",
    "    choose_model = index\n",
    "    key, model_name = available_models[choose_model - 1]\n",
    "    all_true = df[\"labels\"].tolist()\n",
    "    all_pred = df[key].tolist()\n",
    "    report = classification_report(all_true, all_pred, digits=4)\n",
    "    print(f\"\\nCLASSIFICATION REPORT: {key}\")\n",
    "    print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cms",
   "language": "python",
   "name": "cms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
