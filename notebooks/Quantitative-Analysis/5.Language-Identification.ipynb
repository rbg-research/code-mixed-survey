{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9527751e-d7e9-4b17-883c-e015c4b37886",
   "metadata": {},
   "source": [
    "# Import required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2069d80d-a131-458e-9b91-36ba0322c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a9b88-5695-417a-9cc4-c300ccff12bc",
   "metadata": {},
   "source": [
    "# Path Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d2945a-2abf-43ad-8d73-e69724ffd077",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../../data/Language-Identification/\"\n",
    "language_pairs = {\n",
    "    \"lid_hineng\": \"Hindi-English\",\n",
    "    \"lid_msaea\": \"Modern Standard Arabic - EgyptArabic\",\n",
    "    \"lid_nepeng\": \"Nepali-English\",\n",
    "    \"lid_spaeng\": \"Spanish-English\"\n",
    "}\n",
    "\n",
    "ground_truth_csv = os.path.join(root_path, \"gt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd40543-3e02-48eb-9b6a-d75819e46280",
   "metadata": {},
   "source": [
    "# Ground Truth Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbffa702-3da5-4fe5-ad0b-39f96b1765b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(text: str) -> str:\n",
    "    text = re.sub(r'https?://\\S+', '', text)\n",
    "    text = re.sub(r'^RT\\s*:\\s*', '', text)\n",
    "    text = re.sub(r'&\\w+;', ' ', text)\n",
    "    text = re.sub(r'&#\\d+;', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\u0600-\\u06FF]', '', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def parse_conll_for_lid():\n",
    "    words = []\n",
    "    labels = []\n",
    "    for key in language_pairs:\n",
    "        test_file = os.path.join(root_path, key, \"dev.conll\")\n",
    "        lang1 = \"English\"\n",
    "        if key == \"lid_hineng\":\n",
    "            lang2 = \"Hindi\"\n",
    "        elif key == \"lid_msaea\":\n",
    "            lang1 = \"Modern Standard Arabic\"\n",
    "            lang2 = \"Egypt Arabic\"\n",
    "        elif key == \"lid_nepeng\":\n",
    "            lang2 = \"Nepali\"\n",
    "        elif key == \"lid_spaeng\":\n",
    "            lang2 = \"Nepali\"\n",
    "        else:\n",
    "            raise \"Unsupport language pairs\"\n",
    "    \n",
    "        with open(test_file, \"r+\") as read_file:\n",
    "            text = read_file.read()\n",
    "            text = text.replace(\"lang1\", lang1)\n",
    "            text = text.replace(\"lang2\", lang2)\n",
    "            lines = text.split(\"\\n\")\n",
    "            \n",
    "        lines = [line for line in lines if len(line.strip())>1]\n",
    "        \n",
    "        for idx, line in enumerate(lines):\n",
    "            if \"sent_enum\" in line:\n",
    "                pass\n",
    "            else:\n",
    "                items = line.split()\n",
    "                word = items[0].strip()\n",
    "                # word = preprocess_tweet(word)\n",
    "                label = \" \".join(items[1:]).strip()\n",
    "                # if len(word) >= 1:\n",
    "                words.append(word)\n",
    "                labels.append(label)\n",
    "    temp_df = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"words\": words,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "    )\n",
    "    return temp_df            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0ad1d15-3afa-4e35-b0e3-49dfa85bffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(ground_truth_csv):\n",
    "    df = pd.read_csv(ground_truth_csv)\n",
    "else:\n",
    "    df = parse_conll_for_lid()\n",
    "    df.to_csv(ground_truth_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "486bca3d-f750-47d2-a6e1-8faf393282ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ZahirJ</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@BinyavangaW</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Loved</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ending</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97083</th>\n",
       "      <td>OLEEE</td>\n",
       "      <td>Nepali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97084</th>\n",
       "      <td>!!!</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97085</th>\n",
       "      <td>ABOTABOTABOTABOOOOOO</td>\n",
       "      <td>Nepali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97086</th>\n",
       "      <td>!!!!!!</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97087</th>\n",
       "      <td>PIPIPPIPI</td>\n",
       "      <td>unk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97088 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      words   labels\n",
       "0                   @ZahirJ    other\n",
       "1              @BinyavangaW    other\n",
       "2                     Loved  English\n",
       "3                       the  English\n",
       "4                    ending  English\n",
       "...                     ...      ...\n",
       "97083                 OLEEE   Nepali\n",
       "97084                   !!!    other\n",
       "97085  ABOTABOTABOTABOOOOOO   Nepali\n",
       "97086                !!!!!!    other\n",
       "97087             PIPIPPIPI      unk\n",
       "\n",
       "[97088 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d2057c-3c62-4d2e-ac06-cf3f5df8dcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ne',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'fw',\n",
       " 'ambiguous',\n",
       " 'Egypt Arabic',\n",
       " 'unk',\n",
       " 'Modern Standard Arabic',\n",
       " 'Nepali',\n",
       " 'Hindi',\n",
       " 'other']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(df.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ccbd99-604b-4795-af14-a2c207fe6b34",
   "metadata": {},
   "source": [
    "# Language Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76dd3b11-b81a-4218-ae7b-a38278057684",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models = [\n",
    "    (\"xlmr\", \"xlm-roberta-base\"),\n",
    "    (\"mdeberta\", \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"),\n",
    "    (\"labse\", \"setu4993/LaBSE\"),\n",
    "    (\"muril\", \"google/muril-base-cased\")\n",
    "]\n",
    "\n",
    "hf_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0388f8b8-d199-4b85-bec7-e0fbe56298a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode sentences\n",
    "def encode_sentences(tokenizer, model, sentences, device):\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "    # print(encoded_input)\n",
    "    encoded_input = encoded_input.to(device)\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    return model_output.last_hidden_state[:, 0, :]\n",
    "\n",
    "# Zero-shot prediction\n",
    "def zero_shot_predict_single(text, tokenizer, model, label_embeddings, labels, device):\n",
    "    text_embedding = encode_sentences(tokenizer, model, [text], device)\n",
    "    cosine_similarities = F.cosine_similarity(text_embedding.unsqueeze(1), label_embeddings.unsqueeze(0), dim=2)\n",
    "    predicted_index = torch.argmax(cosine_similarities, dim=1).item()\n",
    "    return labels[predicted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06900701-9546-4b5a-abf6-a5c6395f0cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:902: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception for model xlm-roberta-base at idx 76474: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:902: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception for model MoritzLaurer/mDeBERTa-v3-base-mnli-xnli at idx 76474: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:902: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception for model setu4993/LaBSE at idx 76474: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:902: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception for model google/muril-base-cased at idx 76474: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).\n"
     ]
    }
   ],
   "source": [
    "#  Choose the model here (1-based index): 1 = XLM-R, 2 = mDeBERTa, 3 = LaBSE, 4 = MuRIL\n",
    "for index in range(1,5):\n",
    "    df = pd.read_csv(ground_truth_csv)\n",
    "    choose_model = index\n",
    "    key, model_name = available_models[choose_model - 1]\n",
    "    labels_list = ['Modern Standard Arabic', 'Hindi', 'Egypt Arabic', 'English', 'Nepali', 'ne',  'other', 'unk', 'ambiguous', 'mixed', 'fw']\n",
    "    descriptions = [\n",
    "        \"This word is in Modern Standard Arabic\",\n",
    "        \"This word is in Hindi\",\n",
    "        \"This word is in Egypt Arabic\",\n",
    "        \"This word is in English\",\n",
    "        \"This word is in Nepali\",\n",
    "        \"This word is a named entity such as a person, hashtag, or organization.\",\n",
    "        \"This token is a special token like a mention or punctuation.\",\n",
    "        \"Unknown – the language of the token could not be determined.\",\n",
    "        \"it's unclear which language the token belongs to.\",\n",
    "        \"the token contains parts from two languages\",\n",
    "        \"this token is a word borrowed from a other language.\"\n",
    "    ]\n",
    "    if key not in df.columns:\n",
    "        device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hf_token)\n",
    "        model = AutoModel.from_pretrained(model_name, use_auth_token=hf_token).to(device)\n",
    "        model.eval()\n",
    "\n",
    "        label_embeddings = encode_sentences(tokenizer, model, descriptions, device)\n",
    "\n",
    "        predictions = []\n",
    "        for idx, item in enumerate(df[\"words\"].tolist()):\n",
    "            try:\n",
    "                pred = zero_shot_predict_single(item, tokenizer, model, label_embeddings, labels_list, device)\n",
    "                predictions.append(pred)\n",
    "            except Exception as e:\n",
    "                print(f\"Exception for model {model_name} at idx {idx}: {e}\")\n",
    "                predictions.append(\"other\")\n",
    "\n",
    "        df[key] = predictions\n",
    "        df.to_csv(ground_truth_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ac2562a-142a-4bc0-b132-1aeef5055221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English',\n",
       " 'ne',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'ne',\n",
       " 'mixed',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'mixed',\n",
       " 'Egypt Arabic',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'mixed',\n",
       " 'Nepali',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'ne',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Egypt Arabic',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Egypt Arabic',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'ne',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Egypt Arabic',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'unk',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'ne',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'Nepali',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'ne',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'Nepali',\n",
       " 'English',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'fw',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'English',\n",
       " 'mixed',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'mixed',\n",
       " 'English',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de881038-9912-4d24-8b9c-63db171a460f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375775a1-d2b4-4c79-9f58-ead29647f4f9",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d04e57e6-876e-458d-bda3-a7b8f222646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ground_truth_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4773ec5-5ed6-4133-a6d5-411c1b6d628f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CLASSIFICATION REPORT: xlmr\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "          Egypt Arabic     0.0401    0.4168    0.0731      4100\n",
      "               English     0.4421    0.0195    0.0373     31358\n",
      "                 Hindi     0.0785    0.0178    0.0291      3306\n",
      "Modern Standard Arabic     0.0000    0.0000    0.0000     13317\n",
      "                Nepali     0.2905    0.3257    0.3071     23372\n",
      "             ambiguous     0.0006    0.0138    0.0011       217\n",
      "                    fw     0.0000    0.0000    0.0000        31\n",
      "                 mixed     0.0006    0.2667    0.0012        30\n",
      "                    ne     0.0000    0.0000    0.0000      4892\n",
      "                 other     0.0000    0.0000    0.0000     16431\n",
      "                   unk     0.0000    0.0000    0.0000        34\n",
      "\n",
      "              accuracy                         0.1030     97088\n",
      "             macro avg     0.0775    0.0964    0.0408     97088\n",
      "          weighted avg     0.2171    0.1030    0.0901     97088\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ubuntu/environments/cms/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CLASSIFICATION REPORT: mdeberta\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "          Egypt Arabic     0.0579    0.0083    0.0145      4100\n",
      "               English     0.2313    0.4925    0.3148     31358\n",
      "                 Hindi     0.0000    0.0000    0.0000      3306\n",
      "Modern Standard Arabic     0.0522    0.0010    0.0019     13317\n",
      "                Nepali     0.0104    0.0000    0.0001     23372\n",
      "             ambiguous     0.0007    0.0323    0.0014       217\n",
      "                    fw     0.0000    0.0000    0.0000        31\n",
      "                 mixed     0.0000    0.0000    0.0000        30\n",
      "                    ne     0.0356    0.0315    0.0334      4892\n",
      "                 other     0.0103    0.0029    0.0045     16431\n",
      "                   unk     0.0000    0.0000    0.0000        34\n",
      "\n",
      "              accuracy                         0.1617     97088\n",
      "             macro avg     0.0362    0.0517    0.0337     97088\n",
      "          weighted avg     0.0904    0.1617    0.1050     97088\n",
      "\n",
      "\n",
      "CLASSIFICATION REPORT: labse\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "          Egypt Arabic     0.0505    0.1034    0.0678      4100\n",
      "               English     0.2439    0.0003    0.0006     31358\n",
      "                 Hindi     0.1315    0.0266    0.0443      3306\n",
      "Modern Standard Arabic     0.2293    0.3909    0.2890     13317\n",
      "                Nepali     0.2717    0.0227    0.0419     23372\n",
      "             ambiguous     0.0016    0.1475    0.0032       217\n",
      "                    fw     0.0000    0.0000    0.0000        31\n",
      "                 mixed     0.0000    0.0000    0.0000        30\n",
      "                    ne     0.0391    0.0300    0.0340      4892\n",
      "                 other     0.2485    0.2300    0.2389     16431\n",
      "                   unk     0.0000    0.0000    0.0000        34\n",
      "\n",
      "              accuracy                         0.1052     97088\n",
      "             macro avg     0.1105    0.0865    0.0654     97088\n",
      "          weighted avg     0.2263    0.1052    0.0964     97088\n",
      "\n",
      "\n",
      "CLASSIFICATION REPORT: muril\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "          Egypt Arabic     0.1465    0.0505    0.0751      4100\n",
      "               English     0.3637    0.8096    0.5019     31358\n",
      "                 Hindi     0.0743    0.0269    0.0395      3306\n",
      "Modern Standard Arabic     0.6554    0.2317    0.3423     13317\n",
      "                Nepali     0.5374    0.0418    0.0776     23372\n",
      "             ambiguous     0.0000    0.0000    0.0000       217\n",
      "                    fw     0.0004    0.0645    0.0008        31\n",
      "                 mixed     0.0005    0.2000    0.0011        30\n",
      "                    ne     0.0436    0.0129    0.0199      4892\n",
      "                 other     0.6265    0.0215    0.0417     16431\n",
      "                   unk     0.0000    0.0000    0.0000        34\n",
      "\n",
      "              accuracy                         0.3108     97088\n",
      "             macro avg     0.2226    0.1327    0.1000     97088\n",
      "          weighted avg     0.4537    0.3108    0.2403     97088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index in range(1,5):\n",
    "    choose_model = index\n",
    "    key, model_name = available_models[choose_model - 1]\n",
    "    all_true = df[\"labels\"].tolist()\n",
    "    all_pred = df[key].tolist()\n",
    "    report = classification_report(all_true, all_pred, digits=4)\n",
    "    print(f\"\\nCLASSIFICATION REPORT: {key}\")\n",
    "    print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cms",
   "language": "python",
   "name": "cms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
